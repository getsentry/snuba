<img src="/snuba/static/img/snuba.svg" width="150" height="71"/>

A service providing fast event searching, filtering and aggregation on arbitrary fields.

## Requirements

Snuba assumes a Clickhouse server endpoint at `CLICKHOUSE_SERVER` (default `localhost:9000`).

## Install / Run

    mkvirtualenv snuba

    # Run API server
    ./bin/api

## API

Snuba exposes an HTTP API with the following endpoints.

- [/](/): Shows this page.
- [/dashboard](/dashboard): Query dashboard
- [/query](/query): Endpoint for querying clickhouse.
- [/config](/config): Console for runtime config options

## Settings

Settings are found in `settings.py`

- `CLICKHOUSE_SERVER` : The endpoint for the clickhouse service.
- `CLICKHOUSE_TABLE` : The clickhouse table name.

## Tests

    docker run -d -p 9000:9000 -p 9009:9009 -p 8123:8123 \
      --name clickhouse-server --ulimit nofile=262144:262144 yandex/clickhouse-server

    pip install -r requirements-py2.txt
    python setup.py develop

    pytest

## Querying

Try out queries on the [query console](/query). Queries are submitted as a JSON
body to the [/query](/query) endpoint.

### The Query Payload

An example query body might look like:

    {
        "project":[1,2],
        "selected_columns": ["tags[environment]"],
        "aggregations": [
            ["max", "received", "last_seen"]
        ],
        "conditions": [
            ["tags[environment]", "=", "prod"]
        ],
        "from_date": "2011-07-01T19:54:15",
        "to_date": "2018-07-06T19:54:15"
        "granularity": 3600,
        "groupby": ["issue", "time"],
        "having": [],
        "issues": [],
    }

#### selected_columns, groupby

`groupby` is a list of columns (or column aliases) that will be translated into
a SQL `GROUP BY` clause. These columns are automatically included in the query
output.  `selected_columns` is a list of additional columns that should be added
to the `SELECT` clause.

Trying to use both of these in the same query will probably result in an invalid
query, as you cannot select a bare column, while grouping by another column, as
the value of the extra selected column for a given output row (group) would be
ambiguous.

#### aggregations

This is an array of 3-tuples of the form:

    [function, column, alias]

which is transformed into the SQL:

    function(column) AS alias

Some aggregation function are generated by other functions, eg topK. so an
example query would send:

    ["topK(5)", "environment", "top_five_envs"]

To produce the SQL:

    topK(5)(environment) AS top_five_envs

Count is a somewhat special case, it doesn't have a column argument, and is
specified as "count()", not "count".

    ["count()", null, "item_count"]

Aggregations are also included in the output columns automatically.


#### conditions

#### from_date / to_date

#### granularity

#### having

#### issues

#### project

### Issues / Groups

Because events can be reassigned to different issues through merging, and
because snuba does not support updates, we cannot store the issue id for an
event in snuba. If you want to filter or group by `issue`, you need to pass a
list of `issues` into the query.  This list is a mapping from issue ids to the
event `primary_hash`es in that issue. Snuba automatically expands this mapping
into the query so that filters/grouping on `issue` will just work.

### Tags

Event tags are stored in one of 2 ways. Promoted tags are the ones we expect to
be queried often and as such are stored as top level columns. The list of
promoted tag columns is defined in settings and is somewhat fixed in the
schema. The rest of an event's tags are stored as a key-value map.  In practice
this is implemented as 2 columns of type Array(String), called `tags.key` and
`tags.value`

The snuba service provides 2 mechanisms for abstracting this tiered tag
structure by providing some special columns that will be resolved to the
correct SQL expression for the type of tag. These mechanisms should generally
not be used in conjunction with each other.

#### When you know the names of the tags you want.

You can use the `tags[name]` anywhere you would use a normal column name in an
expression, and it will resolve to the value of the tag with `name`, regardless
of whether that tag is promoted or not. Use this syntax when you are looking
for a specific named tag. eg.

    # Find all events in production with user_custom_key defined.
    "conditions": [
        ["tags[environment]", "=", "prod"],
        ["tags[custom_user_tag]", "IS NOT NULL"]
    ],
<!-- -->

    # Find the number of unique environments
    "aggregations": [
        ["uniq", "tags[environment]", "unique_envs"],
    ],

#### When you don't know the name, or want to query all tags.

These are virtual columns that can be used to get results when the names of the
tags are not explicitly known. Using `tags_key` or `tags_value` in an
expression will expand all of the promoted and non-promoted tags so that there
is one row per tag (an array-join in Clickhouse terms). For each row, the name
of the tag will be in the `tags_key` column, and the value in the `tags_value`
column.

    # Find the top 5 most often used tags
    "aggregations": [
        ["topK(5)", "tags_key", "top_tag_keys"],
    ],
<!-- -->

    # Find any tags whose *value* is `bar`
    "conditions": [
        ["tags_value", "=", "bar"],
    ],


Note, when using this expression. the thing you are counting is tags, not events, so if you
have 10 events, each of which has 10 tags, then a `count()` of `tags_key` will return 100.
