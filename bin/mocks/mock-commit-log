#!/usr/bin/env python
import argparse
import os

from arroyo import Topic
from arroyo.backends.kafka import KafkaPayload
from arroyo.backends.local.backend import LocalBroker as Broker
from arroyo.backends.local.storages.abstract import TopicExists
from arroyo.backends.local.storages.file import FileMessageStorage

from snuba.datasets.entities import EntityKey
from snuba.datasets.entities.factory import get_entity

parser = argparse.ArgumentParser(description="Mock commit log data")
parser.add_argument(
    "--entity",
    type=str,
    help="Entity's commit log to write data to",
    dest="entity",
    choices=["events"],
    default="events",
)

parsed = parser.parse_args()
entity_name = parsed.entity

entity = get_entity(EntityKey(entity_name))
storage = entity.get_writable_storage()
assert storage is not None
stream_loader = storage.get_table_writer().get_stream_loader()
commit_log_topic_spec = stream_loader.get_commit_log_topic_spec()
assert commit_log_topic_spec is not None

# Create the commit log topic
try:
    directory_path = os.getcwd() + "/.broker_data"
    broker: Broker[KafkaPayload] = Broker(FileMessageStorage(directory_path))
    broker.create_topic(Topic(commit_log_topic_spec.topic_name), partitions=1)
except TopicExists:
    pass
