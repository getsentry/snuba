
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Snuba Consumers &#8212; Snuba 26.3.0.dev0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Dataset Configuration" href="../configuration/overview.html" />
    <link rel="prev" title="Snuba Query Processing" href="queryprocessing.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="snuba-consumers">
<h1>Snuba Consumers<a class="headerlink" href="#snuba-consumers" title="Permalink to this heading">¶</a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">consumer</span></code> is still the easiest way to deploy a consumer for a new
dataset, as the message processor can be written in Python.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">rust-consumer</span> <span class="pre">--use-rust-processor</span></code> can be used to serve the needs
of high-throughput datasets, as it sidesteps all problems with Python
concurrency. For that, the message processor needs to be written to Rust.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">rust-consumer</span> <span class="pre">--use-python-processor</span></code> is an experiment that attempts
to consolidate both consumers’ logic, so that we can eventually remove the
code beneath <code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">consumer</span></code>. It is not deployed anywhere in prod.</p></li>
<li><p>In order to port a dataset fully to Rust, register a new message processor in
<code class="docutils literal notranslate"><span class="pre">rust_snuba/src/processors/mod.rs</span></code> and add it to
<code class="docutils literal notranslate"><span class="pre">tests/consumers/test_message_processors.py</span></code>. Later, use
<code class="docutils literal notranslate"><span class="pre">RustCompatProcessor</span></code> to get rid of the Python implementation.</p></li>
</ul>
</section>
<section id="message-processors">
<h2>Message processors<a class="headerlink" href="#message-processors" title="Permalink to this heading">¶</a></h2>
<p>Each storage in Snuba defines a conversion function mapping the layout of a
Kafka message to a list of ClickHouse rows.</p>
<p>Message processors are defined in <code class="xref py py-mod docutils literal notranslate"><span class="pre">snuba.dataset.processors</span></code>, and
need to subclass from
<code class="xref py py-class docutils literal notranslate"><span class="pre">snuba.dataset.processors.DatasetMessageProcessor</span></code>. Just by
subclassing, their name becomes available for reference in
<code class="docutils literal notranslate"><span class="pre">snuba/datasets/configuration/*/storages/*.yaml</span></code>.</p>
</section>
<section id="python-consumers">
<h2>Python consumers<a class="headerlink" href="#python-consumers" title="Permalink to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">consumer</span></code> runs the Python consumer. It uses the Python message
processor mentioned above to convert Kafka messages into rows, batches those
rows up into larger <code class="docutils literal notranslate"><span class="pre">INSERT</span></code>-statements, sends off the <code class="docutils literal notranslate"><span class="pre">INSERT</span></code> statement
to the cluster defined in <code class="docutils literal notranslate"><span class="pre">settings.py</span></code>.</p>
</section>
<section id="test-endpoints">
<h2>Test endpoints<a class="headerlink" href="#test-endpoints" title="Permalink to this heading">¶</a></h2>
<p>In sentry we have a lot of tests that want to insert into ClickHouse. Tests
have certain requirements that our Kafka consumers can’t meet and which don’t
apply to production:</p>
<ul class="simple">
<li><p>They require strong consistency, as they want to run a handful of queries +
assertions, then insert a few rows, wait for them to be inserted, then run
some more assertions depending on that new data.</p></li>
<li><p>Because tests wait for every insert synchronously, insertion latency is
really important, while throughput isn’t.</p></li>
<li><p>Basically, people want to write e2e tests involving Snuba similarly to how
tests involving relational DBs in Django ORM are being written.</p></li>
</ul>
<p>Every storage can be inserted into and wiped using HTTP as well, using the
endpoints defined in <code class="docutils literal notranslate"><span class="pre">snuba.web.views</span></code> prefixed with <code class="docutils literal notranslate"><span class="pre">/tests/</span></code>. Those
endpoints use the same message processors as the Python consumer, but there’s
no batching at all. One HTTP request gets directly translated into a blocking
<code class="docutils literal notranslate"><span class="pre">INSERT</span></code>-statement towards ClickHouse.</p>
</section>
<section id="rust-consumers">
<h2>Rust consumers<a class="headerlink" href="#rust-consumers" title="Permalink to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">rust-consumer</span></code> runs the Rust consumer. It comes in two flavors, “pure
Rust” and “hybrid”:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--use-rust-processor</span></code> (“pure rust”) will attempt to find and load a Rust
version of the message processor. There is a mapping from Python class names
like <code class="docutils literal notranslate"><span class="pre">QuerylogProcessor</span></code> to the relevant function, defined in
<code class="docutils literal notranslate"><span class="pre">rust_snuba/src/processors/mod.rs</span></code>. If that function exists, it is being
used. The resulting running consumer is sometimes 20x faster than the Python
version.</p>
<p>If a Rust port of the message processor can’t be found, the consumer silently
falls back to the second flavor:</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--use-python-processor</span></code> (“hybrid”) will use the Python message processor from
within Rust. For this mode, no dataset-specific logic has to be ported to
Rust, but at the same time the performance benefits of using a Rust consumer
are negligible.</p></li>
</ul>
</section>
<section id="python-message-processor-compat-shims">
<h2>Python message processor compat shims<a class="headerlink" href="#python-message-processor-compat-shims" title="Permalink to this heading">¶</a></h2>
<p>Even when a dataset is being processed with 100% Rust in prod (i.e. pure-rust
consumer is being used), we still have those <code class="docutils literal notranslate"><span class="pre">/tests/</span></code> API endpoints, as
there is a need for testing, and so there still needs to be a Python
implementation of the same message processor. For this purpose
<code class="docutils literal notranslate"><span class="pre">RustCompatProcessor</span></code> can be used as a baseclass that will delegate all logic
back into Rust. This means that:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">consumer</span></code> will connect to Kafka using Python, but process messages
in Rust (using Python’s multiprocessing)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">rust-consumer</span> <span class="pre">--use-python-processor</span></code> makes no sense to deploy
anywhere, as it will connect to Kafka using Rust, then perform a roundtrip
through Python only to call Rust business logic again.</p></li>
</ul>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Permalink to this heading">¶</a></h2>
<p>When porting a message processor to Rust, we validate equivalence to Python by:</p>
<ol class="arabic simple">
<li><p>Registering the Python class in
<code class="docutils literal notranslate"><span class="pre">tests/consumers/test_message_processors.py</span></code>, where it will run all
payloads from <code class="docutils literal notranslate"><span class="pre">sentry-kafka-schemas</span></code> against both message processors and
assert the same rows come back. If there is missing test coverage, it’s
preferred to add more payloads to <code class="docutils literal notranslate"><span class="pre">sentry-kafka-schemas</span></code> than to write
custom tests.</p></li>
<li><p>Remove the Python message processor and replace it with
<code class="docutils literal notranslate"><span class="pre">RustCompatProcessor</span></code>, in which case the existing Python tests (of both
Snuba and Sentry) will be directly run against the Rust message processor.</p></li>
</ol>
</section>
<section id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this heading">¶</a></h2>
<section id="python">
<h3>Python<a class="headerlink" href="#python" title="Permalink to this heading">¶</a></h3>
<p>In order to get around the GIL, Python consumers use arroyo’s multiprocessing
support to be able to use multiple cores. This comes with significant
serialization overhead and an amount of complexity that is out of scope for
this document.</p>
</section>
<section id="pure-rust">
<h3>Pure Rust<a class="headerlink" href="#pure-rust" title="Permalink to this heading">¶</a></h3>
<p>Despite the name this consumer is still launched from the Python CLI. The way
this works is that all Rust is compiled into a shared library exposing a
<code class="docutils literal notranslate"><span class="pre">consumer()</span></code> function, and packaged using <code class="docutils literal notranslate"><span class="pre">maturin</span></code> into a Python wheel.
The Python CLI for <code class="docutils literal notranslate"><span class="pre">snuba</span> <span class="pre">rust-consumer</span></code>:</p>
<ol class="arabic simple">
<li><p>Parses CLI arguments</p></li>
<li><p>Resolves config (loads storages, clickhouse settings)</p></li>
<li><p>Builds a new config JSON payload containing only information relevant to the
Rust consumer (name of message processor, name of physical Kafka topic, name
of ClickHouse table, and connection settings)</p></li>
<li><p>calls <code class="docutils literal notranslate"><span class="pre">rust_snuba.consumer(config)</span></code>, at which point Rust takes over the
process entirely.</p></li>
</ol>
<p>Concurrency model in pure-rust is very simple: The message processors run on a
<code class="docutils literal notranslate"><span class="pre">tokio::Runtime</span></code>, which means that we’re using regular OS threads in order to
use multiple cores. The GIL is irrelevant since no Python code runs.</p>
</section>
<section id="hybrid">
<h3>Hybrid<a class="headerlink" href="#hybrid" title="Permalink to this heading">¶</a></h3>
<p>Hybrid consumer is mostly the same as pure-rust. The main difference is that it
calls back into Python message processors. How that works is work-in-progress,
but fundamentally it is subject to the same concurrency problems as the regular
pure-Python consumer, and is therefore forced to spawn subprocesses and perform
IPC one way or the other.</p>
<p>Since the consumer is launched from the Python CLI, it will find the Python
interpreter already initialized, and does not have to re-import Snuba again
(except in subprocesses)</p>
<p>Signal-handling is a bit tricky. Since no Python code runs for the majority of
the consumer’s lifetime, Python’s signal handlers cannot run. This also means
that the Rust consumer has to register its own handler for <code class="docutils literal notranslate"><span class="pre">Ctrl-C</span></code>, but
doing so also means that Python’s own signal handlers are completely ignored.
This is fine for the pure-rust case, but in the Hybrid case we have some Python
code still running. For that Python code, <code class="docutils literal notranslate"><span class="pre">KeyboardInterrupt</span></code> does
not work.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../index.html">
              <img class="logo" src="../_static/snuba.svg" alt="Logo"/>
            </a></p>
<h1 class="logo"><a href="../index.html">Snuba</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../getstarted.html">Getting started with Snuba</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Snuba Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html#snuba-within-a-sentry-deployment">Snuba within a Sentry Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="datamodel.html">Snuba Data Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="slicing.html">Snuba Data Slicing (under development)</a></li>
<li class="toctree-l1"><a class="reference internal" href="slicing.html#configuring-a-slice">Configuring a slice</a></li>
<li class="toctree-l1"><a class="reference internal" href="slicing.html#working-in-a-sliced-environment">Working in a Sliced Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="queryprocessing.html">Snuba Query Processing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Snuba Consumers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration/overview.html">Dataset Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../query/overview.html">Querying Snuba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../language/snql.html">The SnQL query language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../language/mql.html">The MQL query language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migrations/modes.html">Snuba Migration Modes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/environment.html">Snuba development environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clickhouse/topology.html">ClickHouse Topology Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clickhouse/schema_design.html">ClickHouse Schema Design Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../clickhouse/supported_versions.html">ClickHouse supported versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html#regular-transaction-profiling">Regular transaction profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html#on-demand-profiling">On-demand profiling</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="queryprocessing.html" title="previous chapter">Snuba Query Processing</a></li>
      <li>Next: <a href="../configuration/overview.html" title="next chapter">Dataset Configuration</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Sentry Team and Contributors.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.1.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/architecture/consumer.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>